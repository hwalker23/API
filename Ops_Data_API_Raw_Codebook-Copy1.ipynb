{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish accounts. Fill out variables here as needed. i.e. project/awardee/pmi_account/service_account\n",
    "# Once you save this file, you don't have to retype these.\n",
    "\n",
    "project = \"all-of-us-rdr-stable\" # type in environment if not stable\n",
    "awardee = \"TEST\" # fill in your awardee\n",
    "pmi_account = \"henry.walker@pmi-ops.org\" # update your pmi-ops account.\n",
    "service_account = \"awardee-test@all-of-us-ops-data-api-stable.iam.gserviceaccount.com\" #update to your service account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Activated service account credentials for: [awardee-test@all-of-us-ops-data-api-stable.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "# Authentication. This cell creates a key for your service account, you don't need to do anything.\n",
    "# If you are running this notebook on your local system (the legacy method) you can un-comment the following line to create\n",
    "# a service account key that is called 'gcloud_key.json'. Otherwise you should have this key in the file structure already.\n",
    "results = !gcloud -q iam service-accounts keys create --account $pmi_account --project $project --iam-account $service_account gcloud_key.json\n",
    "!gcloud -q auth activate-service-account --key-file=gcloud_key.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication Token Ready!\n"
     ]
    }
   ],
   "source": [
    "# Get Oauth Token, refresh as needed.\n",
    "token = !gcloud -q auth print-access-token\n",
    "token = token[0]\n",
    "headers = {'content-type': 'application/json', 'Authorization': 'Bearer {0}'.format(token)}\n",
    "print('Authentication Token Ready!') if token.startswith('ya') else 'Authentication Token Error!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'version_id': '1-148-3'}\n"
     ]
    }
   ],
   "source": [
    "# Make request to get API version. This is the current RDR version for reference\n",
    "import requests\n",
    "resp = requests.get('http://all-of-us-rdr-prod.appspot.com/rdr/v1/', headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def pull_api_data(headers, url):\n",
    "    resp = requests.get(url, headers=headers)\n",
    " #   print(f\"Response2 : {resp} from {url}\")\n",
    "    ps_data = None\n",
    "    if not resp or resp.status_code != 200:\n",
    "        print('Error: api request failed.\\n\\n{0}.'.format(resp.text if resp else 'Unknown error.'))\n",
    "        print(\"Did you run  gcloud -q auth print-access-token ? \")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        ps_data = resp.json()\n",
    "    return ps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3204 records for your query.....retrieving data in 3 batches\n",
      "\n",
      "Retrieving next set of records ... batch  = 1\n",
      "Retrieving next set of records ... batch  = 2\n",
      "Retrieving next set of records ... batch  = 3\n",
      "Retrieving last batch....\n",
      "\n",
      "Success: retrieved 3204 records.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas\n",
    "\n",
    "# Set the # of participants that will be pulled in each batch.\n",
    "\n",
    "count = 1000\n",
    "\n",
    "# Set the URL variable. You can change parameters of the url as needed.\n",
    "# See https://github.com/all-of-us/raw-data-repository/blob/master/opsdataAPI.md for documentation of this api.\n",
    "\n",
    "url = 'https://{0}.appspot.com/rdr/v1/ParticipantSummary?_sort=lastModified&organization=SOUTHERN_UAB&_includeTotal=true&_count={1}&awardee={2}'.format(project, count, awardee)\n",
    "\n",
    "# Call pull_api_data function and store the result in variable \"ps_data\"\n",
    "\n",
    "ps_data = pull_api_data(headers, url)\n",
    "\n",
    "# The variable \"link_data\" is set to the value stored in the \"link\" array in the first index of ps_data (which is a json file)\n",
    "\n",
    "link_data = ps_data[\"link\"][0]\n",
    "\n",
    "\n",
    "\n",
    "# The variable \"total\" stores the total number of records that match your query based on the parameters you set in the URL.\n",
    "# Just to note, the parameter _includeTotal=true will need to be included in the URL\n",
    "total = ps_data[\"total\"]\n",
    "num_of_batches = total//count\n",
    "\n",
    "\n",
    "# The variable \"next_url\" is set to the value of \"url\" in the link_data array\n",
    "next_url = link_data['url']\n",
    "\n",
    "print(\"There are {0} records for your query.....retrieving data in {1} batches\\n\".format(total, num_of_batches))\n",
    "    # print(\"LINK\")\n",
    "#print(link_data)\n",
    "#print(f\"Next relation : {link_data['relation']} url : {next_url} \")\n",
    "\n",
    "batch = 1\n",
    "\n",
    "data = []\n",
    "while next_url is not None:\n",
    "    print(f\"Retrieving next set of records ... batch  = {batch}\")\n",
    "    \n",
    "    good_cols = ['ageRange', 'dateOfBirth', 'participantId', 'race', 'sex', 'email', 'site']\n",
    "\n",
    "\n",
    "# loop over participant summary records, insert participant data in same order as good_cols.\n",
    "    for entry in ps_data['entry']:\n",
    "        item = []\n",
    "        for col in good_cols:\n",
    "            for key, val in entry['resource'].items():\n",
    "                if col == key:\n",
    "                    if key == 'dateOfBirth':                    \n",
    "                        item.append(datetime.strptime(val, '%Y-%m-%d'))\n",
    "                    else:\n",
    "                        item.append(val)    \n",
    "        data.append(item)\n",
    "           # insert_postgres(cur, ps_data)\n",
    "           # conn.commit()\n",
    "            # get next set of patient data based on the next url found within the first result set\n",
    "    frame = pandas.DataFrame(data, columns=good_cols)\n",
    "    if next_url:\n",
    "            ps_data = pull_api_data(headers, next_url)\n",
    "    try:\n",
    "        link_data = ps_data[\"link\"][0]\n",
    "        next_url = link_data['url']\n",
    "    except KeyError:\n",
    "        break\n",
    "    batch += 1\n",
    "resp = requests.get(next_url, headers=headers)\n",
    "if not resp or resp.status_code != 200:\n",
    "    print('Error: api request failed.\\n\\n{0}.'.format(resp.text if resp else 'Unknown error.'))\n",
    "else:\n",
    "    ps_data = resp.json()\n",
    "    print('Retrieving last batch....')\n",
    "    print('\\nSuccess: retrieved {0} records.'.format(count*batch+len(ps_data['entry'])))\n",
    "for entry in ps_data['entry']:\n",
    "        item = []\n",
    "        for col in good_cols:\n",
    "            for key, val in entry['resource'].items():\n",
    "                if col == key:\n",
    "                    if key == 'dateOfBirth':                    \n",
    "                        item.append(datetime.strptime(val, '%Y-%m-%d'))\n",
    "                    else:\n",
    "                        item.append(val)    \n",
    "        data.append(item)\n",
    "           # insert_postgres(cur, ps_data)\n",
    "           # conn.commit()\n",
    "            # get next set of patient data based on the next url found within the first result set\n",
    "frame = pandas.DataFrame(data, columns=good_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ageRange</th>\n",
       "      <th>dateOfBirth</th>\n",
       "      <th>participantId</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>email</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85-</td>\n",
       "      <td>1902-10-10 00:00:00</td>\n",
       "      <td>P145474538</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>SexAtBirth_Male</td>\n",
       "      <td>VQA3+DEV+vv9lxfc3d48g7cithv@vibrenthealthtest.com</td>\n",
       "      <td>UNSET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18-24</td>\n",
       "      <td>2000-09-15 00:00:00</td>\n",
       "      <td>P754497553</td>\n",
       "      <td>UNSET</td>\n",
       "      <td>UNSET</td>\n",
       "      <td>VibQA3+DEV+5psbphwd7ygx5iox@gmail.com</td>\n",
       "      <td>UNSET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85-</td>\n",
       "      <td>1933-03-03 00:00:00</td>\n",
       "      <td>P838000487</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>SexAtBirth_Female</td>\n",
       "      <td>HudsonKing@fakeexample.com</td>\n",
       "      <td>hpo-site-generalgenomicstesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18-24</td>\n",
       "      <td>2000-09-15 00:00:00</td>\n",
       "      <td>P212638360</td>\n",
       "      <td>UNSET</td>\n",
       "      <td>UNSET</td>\n",
       "      <td>VibQA3+DEV+sib0gfp95ejat9my@gmail.com</td>\n",
       "      <td>UNSET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85-</td>\n",
       "      <td>1933-03-03 00:00:00</td>\n",
       "      <td>P726051846</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>SexAtBirth_Female</td>\n",
       "      <td>AriaMorgan@fakeexample.com</td>\n",
       "      <td>hpo-site-generalgenomicstesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>85-</td>\n",
       "      <td>1933-01-01 00:00:00</td>\n",
       "      <td>P946449025</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>participant9_testvirtualsite@example.com</td>\n",
       "      <td>testvirtualsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>85-</td>\n",
       "      <td>1933-01-01 00:00:00</td>\n",
       "      <td>P789078173</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>participant0_testvirtualsite@example.com</td>\n",
       "      <td>testvirtualsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>35-44</td>\n",
       "      <td>1988-02-08 00:00:00</td>\n",
       "      <td>P553118358</td>\n",
       "      <td>MORE_THAN_ONE_RACE</td>\n",
       "      <td>SexAtBirth_Female</td>\n",
       "      <td>ptsc.test.persona+49@gmail.com</td>\n",
       "      <td>hpo-site-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>35-44</td>\n",
       "      <td>1983-09-24 00:00:00</td>\n",
       "      <td>P494083999</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>vibrenttester27+293483@gmail.com</td>\n",
       "      <td>hpo-site-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>18-24</td>\n",
       "      <td>1999-02-02 00:00:00</td>\n",
       "      <td>P812262972</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>PMI_Skip</td>\n",
       "      <td>vignetimplementations+k82@gmail.com</td>\n",
       "      <td>UNSET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3204 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ageRange          dateOfBirth participantId                race  \\\n",
       "0         85-  1902-10-10 00:00:00    P145474538               WHITE   \n",
       "1       18-24  2000-09-15 00:00:00    P754497553               UNSET   \n",
       "2         85-  1933-03-03 00:00:00    P838000487            PMI_Skip   \n",
       "3       18-24  2000-09-15 00:00:00    P212638360               UNSET   \n",
       "4         85-  1933-03-03 00:00:00    P726051846            PMI_Skip   \n",
       "...       ...                  ...           ...                 ...   \n",
       "3199      85-  1933-01-01 00:00:00    P946449025            PMI_Skip   \n",
       "3200      85-  1933-01-01 00:00:00    P789078173            PMI_Skip   \n",
       "3201    35-44  1988-02-08 00:00:00    P553118358  MORE_THAN_ONE_RACE   \n",
       "3202    35-44  1983-09-24 00:00:00    P494083999            PMI_Skip   \n",
       "3203    18-24  1999-02-02 00:00:00    P812262972            PMI_Skip   \n",
       "\n",
       "                    sex                                              email  \\\n",
       "0       SexAtBirth_Male  VQA3+DEV+vv9lxfc3d48g7cithv@vibrenthealthtest.com   \n",
       "1                 UNSET              VibQA3+DEV+5psbphwd7ygx5iox@gmail.com   \n",
       "2     SexAtBirth_Female                         HudsonKing@fakeexample.com   \n",
       "3                 UNSET              VibQA3+DEV+sib0gfp95ejat9my@gmail.com   \n",
       "4     SexAtBirth_Female                         AriaMorgan@fakeexample.com   \n",
       "...                 ...                                                ...   \n",
       "3199           PMI_Skip           participant9_testvirtualsite@example.com   \n",
       "3200           PMI_Skip           participant0_testvirtualsite@example.com   \n",
       "3201  SexAtBirth_Female                     ptsc.test.persona+49@gmail.com   \n",
       "3202           PMI_Skip                   vibrenttester27+293483@gmail.com   \n",
       "3203           PMI_Skip                vignetimplementations+k82@gmail.com   \n",
       "\n",
       "                                 site  \n",
       "0                               UNSET  \n",
       "1                               UNSET  \n",
       "2     hpo-site-generalgenomicstesting  \n",
       "3                               UNSET  \n",
       "4     hpo-site-generalgenomicstesting  \n",
       "...                               ...  \n",
       "3199                  testvirtualsite  \n",
       "3200                  testvirtualsite  \n",
       "3201                       hpo-site-a  \n",
       "3202                       hpo-site-a  \n",
       "3203                            UNSET  \n",
       "\n",
       "[3204 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(frame)\n",
    "frame.to_csv(r'C:\\Users\\walkerhp\\Documents\\Ops Data API\\Output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletes the google cloud key created in first step so that you don't hit the Google enforced limit of 10 keys.\n",
    "# We don't typically need this because we no longer create new keys each time it's run.\n",
    "#import os\n",
    "#os.remove('gcloud_key.json')\n",
    "#!gcloud -q iam service-accounts keys delete $key_id --account $pmi_account --iam-account $service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "* Cells will be added/modified by the dev team while working with data stewards to determine specific needs.\n",
    "* You are welcome to add cells to view info in different ways if you're comfortable with Python\n",
    "    * if you ever want to return this notebook to it's original state type `git checkout -- ops_data_api.ipynb` from the ops_data_api directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
